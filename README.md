# Wasm-R3: Record-Reduce-Replay for Realistic and Standalone  WebAssembly Benchmarks

## Introduction

This repository contains supplementary material for the paper "Wasm-R3: Record-Reduce-Replay for Realistic and Standalone  WebAssembly Benchmarks" (OOPSLA'24).

## Hardware Dependencies

Due to our use of x86-64 specific build of certain software, the machine with x86-64 cpu is required.

## Getting Started Guide

To build the artifact, simply run: 
```
git clone --recursive <this repo>
cd wasm-r3
docker build -t wasm-r3 .
```
The image itself is about 11GB on disk and takes around 3 minutes to build, depending on hardware and network connection.

```
docker run -it --cap-add SYS_ADMIN -p 8000:8000 wasm-r3
```

Addition of Linux capability('--cap-add SYS_ADMIN') is required for running Linux perf tool to measure hardware counters.
If you intend to skip this measurement, you can omit this command-line argument.

Publishing of ports('-p 800:8000') is required for sharing the results of the experiment to the host. 
If you intend to inspect the results with a shell only, you can skip this command-line argument.

## Step by Step Instructions

### Container structure 

The container is organized as follows.

- `/home/wasm-r3/`
  - `evaluation-oopsla2024`: Main evaluation scripts. Described in detail below.
  - `tests/`: Contains various scripts used for testing Wasm-R3.
    - `online/`: Contains browser automation scripts used to run Wasm-R3 against real web applications.
  - `src/`: Source code for TypeScript part of Wasm-R3, which contains record and reduce phase.
  - `crates/`: Source code for Rust part of Wasm-R3, which contains replay phase.
  - `binaryen/`: Dependency of Wasm-R3, used for replay optimizations.
  - `wasabi/`: Dependency of Wasm-R3, used for bytecode instrumentation.

## Scripts inside evaluation-oopsla2024 directory

There are 7 evaluation scripts used for the evaluation of Wasm-R3.

- `eval-RQ1-1,RQ3.py`: Runs Wasm-R3 against the real web application and generates replay benchmarks(section 5.2.1). Also logs some auxiliary stats related to trace reduction(section 5.4).
- `eval-RQ1-2.py`: Runs generated replay benchmarks on 6 target engines totalling 17 configurations(section 5.2.2).
- `eval-RQ2-1.py`: Measures record overhead by comparing cpu cycles of uninstrumented and instrumented chromium(section 5.3.1).
- `eval-RQ2-2.py`: Measures replay characteristics by comparing cpu cyles spent in original wasm code and replay function(section 5.3.2).
- `eval-RQ4.py`: Conducts an ablation study of four variants of Wasm-R3 with two replay optimizations enabled(section 5.5).
- `latexify.py`: From raw data `evaluation-oopsla2024/metrics.json`, written by other `eval-*.py` scripts, generate latex tables and pdf figures.
- `eval-latexify-all.sh`: Runs all of the scripts in order.

Note that when running these scripts separately, you need to run `eval-RQ1-1,RQ3.py` before running any other scripts, as other scripts reuse replay benchmarks generated by `eval-RQ1-1,RQ3.py`.

To run everything in one go, simply run

```
python3 evaluation-oopsla2024/eval-latexify-all.py
```

### Detailed description of each evaluation scripts

# Reusability Guide

Among the directories in the container, `src` and `crates` should be considered a core part of the Wasm-R3, which should be reusable for various real-world web applications.

Browser automation scripts inside `tests/online` are meant to be a test code that exercises web applciations that are hosted in the web. If the content of the web application changes, there might be some modifications required to the test script to adjust to the new application. In the extreme circumstance that the web application is no longer hosted, the test scripts might not be reusable.
